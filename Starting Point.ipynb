{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library and Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T19:40:22.503775Z",
     "start_time": "2019-06-14T19:40:22.495169Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import TWB.xliff as xliff\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import queue\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T19:40:51.817825Z",
     "start_time": "2019-06-14T19:40:49.031629Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize unicode characters\n",
    "def NFD(s):\n",
    "        return unicodedata.normalize('NFD', s)\n",
    "\n",
    "# put your data path here\n",
    "# put your data path here\n",
    "data_dir = os.getcwd()\n",
    "data_dir='/home/antonis/TWB_translators/'\n",
    "metadata = pd.read_excel(data_dir + 'Hackathon-for-Good-2019_TWB-Challenge_Metadata.xlsx')\n",
    "\n",
    "# choose only text documents\n",
    "# TODO The metadata contain some files multiple times and the table is almost 3 times the number of documents\n",
    "# Using various combinations of subsets of the columns to get all the 12156 documents did not succeed\n",
    "accepted_documents = metadata.loc[(metadata['Format'] == 'doc') | (metadata['Format'] == 'pdf')].drop_duplicates()\n",
    "\n",
    "# fix some problems with the encoding of special characters in filenames\n",
    "accepted_documents['Filename'] = accepted_documents['Filename'].apply(NFD)\n",
    "\n",
    "# update data path with the sdlxliff directory\n",
    "data_dir += '/hackathon-for-good-2019_TWB-challenge_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T19:40:56.493779Z",
     "start_time": "2019-06-14T19:40:56.453707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Wordcount</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Source_lang</th>\n",
       "      <th>Source_country</th>\n",
       "      <th>Target_lang</th>\n",
       "      <th>Target_country</th>\n",
       "      <th>NGO</th>\n",
       "      <th>Format</th>\n",
       "      <th>System</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-12 00:56:11</td>\n",
       "      <td>109.0</td>\n",
       "      <td>347words.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-12 01:53:23</td>\n",
       "      <td>121.0</td>\n",
       "      <td>387words.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-12 09:30:28</td>\n",
       "      <td>109.0</td>\n",
       "      <td>347words.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-12 12:57:12</td>\n",
       "      <td>121.0</td>\n",
       "      <td>387words.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-12-12 19:04:04</td>\n",
       "      <td>45371.3</td>\n",
       "      <td>Global_Tools_Review_FINAL_Nov2016_graphs_corre...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>ar</td>\n",
       "      <td>SA</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016-12-12 19:04:04</td>\n",
       "      <td>45371.3</td>\n",
       "      <td>Global_Tools_Review_FINAL_Nov2016_graphs_corre...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-12-12 19:04:04</td>\n",
       "      <td>45371.3</td>\n",
       "      <td>Global_Tools_Review_FINAL_Nov2016_graphs_corre...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>es</td>\n",
       "      <td>ES</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-12-19 11:04:31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347words.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-12-19 12:09:22</td>\n",
       "      <td>109.0</td>\n",
       "      <td>347words.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016-12-19 12:10:10</td>\n",
       "      <td>109.0</td>\n",
       "      <td>347words.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-12-26 11:23:43</td>\n",
       "      <td>13295.9</td>\n",
       "      <td>DRAFT_REACH_HTI_Multisector_Assessment_in_Sud_...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>Impact initiatives</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-01-04 08:20:01</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>Executive_Summary_ENG.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>fr</td>\n",
       "      <td>CA</td>\n",
       "      <td>Freedom Now</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>sq</td>\n",
       "      <td>AL</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>ar</td>\n",
       "      <td>SA</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>hy</td>\n",
       "      <td>AM</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>az</td>\n",
       "      <td>AZ</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>be</td>\n",
       "      <td>BY</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>bs</td>\n",
       "      <td>BA</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>bg</td>\n",
       "      <td>BG</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>ca</td>\n",
       "      <td>ES</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>hr</td>\n",
       "      <td>HR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>cs</td>\n",
       "      <td>CZ</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>da</td>\n",
       "      <td>DK</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>et</td>\n",
       "      <td>EE</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>fi</td>\n",
       "      <td>FI</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>de</td>\n",
       "      <td>DE</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>el</td>\n",
       "      <td>GR</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>hi</td>\n",
       "      <td>IN</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2017-01-16 15:35:52</td>\n",
       "      <td>2703.2</td>\n",
       "      <td>What_Now_-_Key_Messages_for_translation_-_Duri...</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>hu</td>\n",
       "      <td>HU</td>\n",
       "      <td>British Red Cross</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34515</th>\n",
       "      <td>2019-05-19 23:48:35</td>\n",
       "      <td>450.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_BT_F_2.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34516</th>\n",
       "      <td>2019-05-19 23:55:30</td>\n",
       "      <td>324.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_BT_M_1.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34517</th>\n",
       "      <td>2019-05-19 23:59:51</td>\n",
       "      <td>487.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_BT_M_2.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34518</th>\n",
       "      <td>2019-05-20 00:01:14</td>\n",
       "      <td>428.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_BT_M_3.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34519</th>\n",
       "      <td>2019-05-20 00:05:14</td>\n",
       "      <td>439.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_RI_F.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34520</th>\n",
       "      <td>2019-05-20 00:11:21</td>\n",
       "      <td>439.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_RI_F.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>2019-05-20 00:12:30</td>\n",
       "      <td>289.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_RI_M.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34522</th>\n",
       "      <td>2019-05-20 09:13:48</td>\n",
       "      <td>866.5</td>\n",
       "      <td>TWB_OnlineSurvey-Final_190520.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34524</th>\n",
       "      <td>2019-05-20 09:52:02</td>\n",
       "      <td>439.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_RI_F.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34525</th>\n",
       "      <td>2019-05-20 09:53:30</td>\n",
       "      <td>289.0</td>\n",
       "      <td>REACH_BGD_JENA_C26_RI_M.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34526</th>\n",
       "      <td>2019-05-20 09:54:35</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>REACH_BGD_JENA_C5_BT_F_1.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34528</th>\n",
       "      <td>2019-05-20 10:02:41</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>REACH_BGD_JENA_C5_BT_F_2.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34530</th>\n",
       "      <td>2019-05-20 10:10:06</td>\n",
       "      <td>324.0</td>\n",
       "      <td>REACH_BGD_JENA_C5_BT_M_1.docx</td>\n",
       "      <td>bn</td>\n",
       "      <td>IN</td>\n",
       "      <td>en</td>\n",
       "      <td>US</td>\n",
       "      <td>Translators without Borders</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34531</th>\n",
       "      <td>2019-05-20 11:51:28</td>\n",
       "      <td>2872.4</td>\n",
       "      <td>2019_05_05NPF_Narrative_Proposal_NN_vn.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>nl</td>\n",
       "      <td>NL</td>\n",
       "      <td>The Womanity Foundation</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34533</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>ar</td>\n",
       "      <td>SA</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34534</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>bg</td>\n",
       "      <td>BG</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34535</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>zh</td>\n",
       "      <td>CN</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34536</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>hr</td>\n",
       "      <td>HR</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34537</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>fr</td>\n",
       "      <td>FR</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34538</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>gu</td>\n",
       "      <td>IN</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34539</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>hi</td>\n",
       "      <td>IN</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34540</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>id</td>\n",
       "      <td>ID</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34541</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>pa</td>\n",
       "      <td>IN</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34542</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>pt</td>\n",
       "      <td>BR</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34543</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>ru</td>\n",
       "      <td>RU</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34544</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>es</td>\n",
       "      <td>MX</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34545</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>sw</td>\n",
       "      <td>KE</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34546</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>tr</td>\n",
       "      <td>TR</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34547</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>uk</td>\n",
       "      <td>UA</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34548</th>\n",
       "      <td>2019-05-20 15:22:33</td>\n",
       "      <td>680.8</td>\n",
       "      <td>Patient_Release_Form_-_Final_4.25.docx</td>\n",
       "      <td>en</td>\n",
       "      <td>GB</td>\n",
       "      <td>vi</td>\n",
       "      <td>VN</td>\n",
       "      <td>Smile Train</td>\n",
       "      <td>doc</td>\n",
       "      <td>Kató 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16914 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  Wordcount  \\\n",
       "0     2016-12-12 00:56:11      109.0   \n",
       "1     2016-12-12 01:53:23      121.0   \n",
       "2     2016-12-12 09:30:28      109.0   \n",
       "3     2016-12-12 12:57:12      121.0   \n",
       "10    2016-12-12 19:04:04    45371.3   \n",
       "11    2016-12-12 19:04:04    45371.3   \n",
       "12    2016-12-12 19:04:04    45371.3   \n",
       "13    2016-12-19 11:04:31        0.0   \n",
       "14    2016-12-19 12:09:22      109.0   \n",
       "15    2016-12-19 12:10:10      109.0   \n",
       "16    2016-12-26 11:23:43    13295.9   \n",
       "23    2017-01-04 08:20:01     1041.0   \n",
       "24    2017-01-16 15:35:52     2703.2   \n",
       "26    2017-01-16 15:35:52     2703.2   \n",
       "28    2017-01-16 15:35:52     2703.2   \n",
       "29    2017-01-16 15:35:52     2703.2   \n",
       "31    2017-01-16 15:35:52     2703.2   \n",
       "33    2017-01-16 15:35:52     2703.2   \n",
       "35    2017-01-16 15:35:52     2703.2   \n",
       "37    2017-01-16 15:35:52     2703.2   \n",
       "38    2017-01-16 15:35:52     2703.2   \n",
       "40    2017-01-16 15:35:52     2703.2   \n",
       "42    2017-01-16 15:35:52     2703.2   \n",
       "44    2017-01-16 15:35:52     2703.2   \n",
       "45    2017-01-16 15:35:52     2703.2   \n",
       "47    2017-01-16 15:35:52     2703.2   \n",
       "48    2017-01-16 15:35:52     2703.2   \n",
       "49    2017-01-16 15:35:52     2703.2   \n",
       "50    2017-01-16 15:35:52     2703.2   \n",
       "52    2017-01-16 15:35:52     2703.2   \n",
       "...                   ...        ...   \n",
       "34515 2019-05-19 23:48:35      450.0   \n",
       "34516 2019-05-19 23:55:30      324.0   \n",
       "34517 2019-05-19 23:59:51      487.0   \n",
       "34518 2019-05-20 00:01:14      428.0   \n",
       "34519 2019-05-20 00:05:14      439.0   \n",
       "34520 2019-05-20 00:11:21      439.0   \n",
       "34521 2019-05-20 00:12:30      289.0   \n",
       "34522 2019-05-20 09:13:48      866.5   \n",
       "34524 2019-05-20 09:52:02      439.0   \n",
       "34525 2019-05-20 09:53:30      289.0   \n",
       "34526 2019-05-20 09:54:35     1149.0   \n",
       "34528 2019-05-20 10:02:41     1074.0   \n",
       "34530 2019-05-20 10:10:06      324.0   \n",
       "34531 2019-05-20 11:51:28     2872.4   \n",
       "34533 2019-05-20 15:22:33      680.8   \n",
       "34534 2019-05-20 15:22:33      680.8   \n",
       "34535 2019-05-20 15:22:33      680.8   \n",
       "34536 2019-05-20 15:22:33      680.8   \n",
       "34537 2019-05-20 15:22:33      680.8   \n",
       "34538 2019-05-20 15:22:33      680.8   \n",
       "34539 2019-05-20 15:22:33      680.8   \n",
       "34540 2019-05-20 15:22:33      680.8   \n",
       "34541 2019-05-20 15:22:33      680.8   \n",
       "34542 2019-05-20 15:22:33      680.8   \n",
       "34543 2019-05-20 15:22:33      680.8   \n",
       "34544 2019-05-20 15:22:33      680.8   \n",
       "34545 2019-05-20 15:22:33      680.8   \n",
       "34546 2019-05-20 15:22:33      680.8   \n",
       "34547 2019-05-20 15:22:33      680.8   \n",
       "34548 2019-05-20 15:22:33      680.8   \n",
       "\n",
       "                                                Filename Source_lang  \\\n",
       "0                                          347words.docx          en   \n",
       "1                                          387words.docx          en   \n",
       "2                                          347words.docx          en   \n",
       "3                                          387words.docx          en   \n",
       "10     Global_Tools_Review_FINAL_Nov2016_graphs_corre...          en   \n",
       "11     Global_Tools_Review_FINAL_Nov2016_graphs_corre...          en   \n",
       "12     Global_Tools_Review_FINAL_Nov2016_graphs_corre...          en   \n",
       "13                                         347words.docx          en   \n",
       "14                                         347words.docx          en   \n",
       "15                                         347words.docx          en   \n",
       "16     DRAFT_REACH_HTI_Multisector_Assessment_in_Sud_...          en   \n",
       "23                            Executive_Summary_ENG.docx          en   \n",
       "24     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "26     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "28     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "29     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "31     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "33     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "35     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "37     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "38     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "40     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "42     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "44     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "45     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "47     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "48     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "49     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "50     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "52     What_Now_-_Key_Messages_for_translation_-_Duri...          en   \n",
       "...                                                  ...         ...   \n",
       "34515                     REACH_BGD_JENA_C26_BT_F_2.docx          bn   \n",
       "34516                     REACH_BGD_JENA_C26_BT_M_1.docx          bn   \n",
       "34517                     REACH_BGD_JENA_C26_BT_M_2.docx          bn   \n",
       "34518                     REACH_BGD_JENA_C26_BT_M_3.docx          bn   \n",
       "34519                       REACH_BGD_JENA_C26_RI_F.docx          bn   \n",
       "34520                       REACH_BGD_JENA_C26_RI_F.docx          bn   \n",
       "34521                       REACH_BGD_JENA_C26_RI_M.docx          bn   \n",
       "34522                 TWB_OnlineSurvey-Final_190520.docx          en   \n",
       "34524                       REACH_BGD_JENA_C26_RI_F.docx          bn   \n",
       "34525                       REACH_BGD_JENA_C26_RI_M.docx          bn   \n",
       "34526                      REACH_BGD_JENA_C5_BT_F_1.docx          bn   \n",
       "34528                      REACH_BGD_JENA_C5_BT_F_2.docx          bn   \n",
       "34530                      REACH_BGD_JENA_C5_BT_M_1.docx          bn   \n",
       "34531        2019_05_05NPF_Narrative_Proposal_NN_vn.docx          en   \n",
       "34533             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34534             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34535             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34536             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34537             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34538             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34539             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34540             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34541             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34542             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34543             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34544             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34545             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34546             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34547             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "34548             Patient_Release_Form_-_Final_4.25.docx          en   \n",
       "\n",
       "      Source_country Target_lang Target_country                          NGO  \\\n",
       "0                 US          fr             FR            British Red Cross   \n",
       "1                 US          fr             FR  Translators without Borders   \n",
       "2                 US          fr             FR            British Red Cross   \n",
       "3                 US          fr             FR            British Red Cross   \n",
       "10                GB          ar             SA            British Red Cross   \n",
       "11                GB          fr             FR            British Red Cross   \n",
       "12                GB          es             ES            British Red Cross   \n",
       "13                US          fr             FR            British Red Cross   \n",
       "14                US          fr             FR  Translators without Borders   \n",
       "15                US          fr             FR            British Red Cross   \n",
       "16                GB          fr             FR           Impact initiatives   \n",
       "23                US          fr             CA                  Freedom Now   \n",
       "24                GB          sq             AL            British Red Cross   \n",
       "26                GB          ar             SA            British Red Cross   \n",
       "28                GB          hy             AM            British Red Cross   \n",
       "29                GB          az             AZ            British Red Cross   \n",
       "31                GB          bn             IN            British Red Cross   \n",
       "33                GB          be             BY            British Red Cross   \n",
       "35                GB          bs             BA            British Red Cross   \n",
       "37                GB          bg             BG            British Red Cross   \n",
       "38                GB          ca             ES            British Red Cross   \n",
       "40                GB          hr             HR            British Red Cross   \n",
       "42                GB          cs             CZ            British Red Cross   \n",
       "44                GB          da             DK            British Red Cross   \n",
       "45                GB          et             EE            British Red Cross   \n",
       "47                GB          fi             FI            British Red Cross   \n",
       "48                GB          de             DE            British Red Cross   \n",
       "49                GB          el             GR            British Red Cross   \n",
       "50                GB          hi             IN            British Red Cross   \n",
       "52                GB          hu             HU            British Red Cross   \n",
       "...              ...         ...            ...                          ...   \n",
       "34515             IN          en             US  Translators without Borders   \n",
       "34516             IN          en             US  Translators without Borders   \n",
       "34517             IN          en             US  Translators without Borders   \n",
       "34518             IN          en             US  Translators without Borders   \n",
       "34519             IN          en             US  Translators without Borders   \n",
       "34520             IN          en             US  Translators without Borders   \n",
       "34521             IN          en             US  Translators without Borders   \n",
       "34522             US          bn             IN  Translators without Borders   \n",
       "34524             IN          en             US  Translators without Borders   \n",
       "34525             IN          en             US  Translators without Borders   \n",
       "34526             IN          en             US  Translators without Borders   \n",
       "34528             IN          en             US  Translators without Borders   \n",
       "34530             IN          en             US  Translators without Borders   \n",
       "34531             GB          nl             NL      The Womanity Foundation   \n",
       "34533             GB          ar             SA                  Smile Train   \n",
       "34534             GB          bg             BG                  Smile Train   \n",
       "34535             GB          zh             CN                  Smile Train   \n",
       "34536             GB          hr             HR                  Smile Train   \n",
       "34537             GB          fr             FR                  Smile Train   \n",
       "34538             GB          gu             IN                  Smile Train   \n",
       "34539             GB          hi             IN                  Smile Train   \n",
       "34540             GB          id             ID                  Smile Train   \n",
       "34541             GB          pa             IN                  Smile Train   \n",
       "34542             GB          pt             BR                  Smile Train   \n",
       "34543             GB          ru             RU                  Smile Train   \n",
       "34544             GB          es             MX                  Smile Train   \n",
       "34545             GB          sw             KE                  Smile Train   \n",
       "34546             GB          tr             TR                  Smile Train   \n",
       "34547             GB          uk             UA                  Smile Train   \n",
       "34548             GB          vi             VN                  Smile Train   \n",
       "\n",
       "      Format  System  \n",
       "0        doc  Kató 1  \n",
       "1        doc  Kató 1  \n",
       "2        doc  Kató 1  \n",
       "3        doc  Kató 1  \n",
       "10       doc  Kató 1  \n",
       "11       doc  Kató 1  \n",
       "12       doc  Kató 1  \n",
       "13       doc  Kató 1  \n",
       "14       doc  Kató 1  \n",
       "15       doc  Kató 1  \n",
       "16       doc  Kató 1  \n",
       "23       doc  Kató 1  \n",
       "24       doc  Kató 1  \n",
       "26       doc  Kató 1  \n",
       "28       doc  Kató 1  \n",
       "29       doc  Kató 1  \n",
       "31       doc  Kató 1  \n",
       "33       doc  Kató 1  \n",
       "35       doc  Kató 1  \n",
       "37       doc  Kató 1  \n",
       "38       doc  Kató 1  \n",
       "40       doc  Kató 1  \n",
       "42       doc  Kató 1  \n",
       "44       doc  Kató 1  \n",
       "45       doc  Kató 1  \n",
       "47       doc  Kató 1  \n",
       "48       doc  Kató 1  \n",
       "49       doc  Kató 1  \n",
       "50       doc  Kató 1  \n",
       "52       doc  Kató 1  \n",
       "...      ...     ...  \n",
       "34515    doc  Kató 1  \n",
       "34516    doc  Kató 1  \n",
       "34517    doc  Kató 1  \n",
       "34518    doc  Kató 1  \n",
       "34519    doc  Kató 1  \n",
       "34520    doc  Kató 1  \n",
       "34521    doc  Kató 1  \n",
       "34522    doc  Kató 1  \n",
       "34524    doc  Kató 1  \n",
       "34525    doc  Kató 1  \n",
       "34526    doc  Kató 1  \n",
       "34528    doc  Kató 1  \n",
       "34530    doc  Kató 1  \n",
       "34531    doc  Kató 2  \n",
       "34533    doc  Kató 1  \n",
       "34534    doc  Kató 1  \n",
       "34535    doc  Kató 1  \n",
       "34536    doc  Kató 1  \n",
       "34537    doc  Kató 1  \n",
       "34538    doc  Kató 1  \n",
       "34539    doc  Kató 1  \n",
       "34540    doc  Kató 1  \n",
       "34541    doc  Kató 1  \n",
       "34542    doc  Kató 1  \n",
       "34543    doc  Kató 1  \n",
       "34544    doc  Kató 1  \n",
       "34545    doc  Kató 1  \n",
       "34546    doc  Kató 1  \n",
       "34547    doc  Kató 1  \n",
       "34548    doc  Kató 1  \n",
       "\n",
       "[16914 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T19:40:58.886201Z",
     "start_time": "2019-06-14T19:40:58.781575Z"
    }
   },
   "outputs": [],
   "source": [
    "# store all sdlxliff filenames into a list\n",
    "document_names = []\n",
    "\n",
    "# trying to get all doc documents based on extensions\n",
    "for document in os.listdir(data_dir):    \n",
    "    if fnmatch.fnmatch(document,'*.sdlxliff'):\n",
    "        if fnmatch.fnmatch(document,'*.doc*'):\n",
    "            document_names.append(document)\n",
    "        elif fnmatch.fnmatch(document,'*.DOC*'):\n",
    "            document_names.append(document)\n",
    "        elif fnmatch.fnmatch(document,'*.txt*'):\n",
    "            document_names.append(document)    \n",
    "        elif fnmatch.fnmatch(document,'*.pdf*'):\n",
    "            document_names.append(document)\n",
    "        elif fnmatch.fnmatch(document,'*.PDF*'):\n",
    "            document_names.append(document)\n",
    "        elif fnmatch.fnmatch(document,'*.odt*'):\n",
    "            document_names.append(document)\n",
    "        elif fnmatch.fnmatch(document,'*.rtf*'):\n",
    "            document_names.append(document)\n",
    "        elif fnmatch.fnmatch(document,'*.dotx*'):\n",
    "            document_names.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T19:45:06.685241Z",
     "start_time": "2019-06-14T19:41:03.510133Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the translated contents of all documents\n",
    "document_contents = []\n",
    "document_source_langs = []\n",
    "document_target_langs = []\n",
    "\n",
    "for i in range(len(document_names)):\n",
    "    document = document_names[i]\n",
    "    temp_xliff = xliff.XLIFF(data_dir + document)\n",
    "    document_contents.append(temp_xliff.target)\n",
    "    document_source_langs.append(temp_xliff.source_lang)\n",
    "    document_target_langs.append(temp_xliff.target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:05:03.809045Z",
     "start_time": "2019-06-14T20:05:03.798135Z"
    }
   },
   "outputs": [],
   "source": [
    "# same unicode fix as for accepted_documents\n",
    "for i in range(len(document_names)):\n",
    "    document_names[i] = NFD(document_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:05:05.654125Z",
     "start_time": "2019-06-14T20:05:05.644405Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove the sdlxliff extension as most files in the metadata are without it\n",
    "filenames = []\n",
    "for i in range(len(document_names)):\n",
    "    filenames.append(document_names[i].replace('.sdlxliff', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:05:28.628928Z",
     "start_time": "2019-06-14T20:05:07.446393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2733\n"
     ]
    }
   ],
   "source": [
    "# find the documents that most probably have no metadata, they are a lot\n",
    "documents_without_metadata = []\n",
    "\n",
    "count = 0\n",
    "for name in filenames:\n",
    "    temp = accepted_documents.loc[accepted_documents['Filename'] == name]\n",
    "    if temp.empty:\n",
    "        # for the special case that the translated version's extension is used\n",
    "        temp2 = accepted_documents.loc[accepted_documents['Filename'] == name + '.sdlxliff']\n",
    "        if temp2.empty:\n",
    "            count += 1       \n",
    "            documents_without_metadata.append(name)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:09:20.216872Z",
     "start_time": "2019-06-14T20:05:33.704409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø·Ø¹Ø§Ù",
      "ÙÙ",
      "_Ø§ÙÙÙÙ",
      ".docx\n",
      "åäººèªå³.docx\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# find the few entries in the metadata that are not in the documents \n",
    "# and the corresponding document filenames for the metadata filenames with wrong encoding\n",
    "import difflib\n",
    "\n",
    "filename_correspondence = {}\n",
    "count = 0\n",
    "for name in list(accepted_documents['Filename'].drop_duplicates()):\n",
    "    if name not in filenames and name not in document_names:\n",
    "        max_similarity = 0.0\n",
    "        corresponding_document = None\n",
    "        for filename in filenames:\n",
    "            # filename letter similarity\n",
    "            seq = difflib.SequenceMatcher(None, filename, name)\n",
    "            if (seq.ratio() > max_similarity):\n",
    "                max_similarity = seq.ratio()\n",
    "                corresponding_document = filename\n",
    "        # this threshold was manually checked and it produces only one false positive\n",
    "        if max_similarity > 0.5:\n",
    "            filename_correspondence[name] = corresponding_document\n",
    "        else:\n",
    "            count += 1\n",
    "            print(name)\n",
    "\n",
    "# delete the false positive \n",
    "del filename_correspondence['Patient_Release_Form_-_Final_4.25.docx']                \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:09:51.550646Z",
     "start_time": "2019-06-14T20:09:50.778799Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function that changes the wrongly encoded metadata filenames\n",
    "def change_names(x):\n",
    "    if x in filename_correspondence.keys():\n",
    "        return filename_correspondence[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# start combining all present features/data per document\n",
    "all_document_data = accepted_documents\n",
    "all_document_data['Filename'] = accepted_documents['Filename'].apply(lambda x: change_names(x))\n",
    "\n",
    "# combine document lines into one list instead of a list of lists for use in a DataFrame column\n",
    "contents = []\n",
    "for i in range(len(document_contents)):\n",
    "    temp = ''\n",
    "    for j in range(len(document_contents[i])):\n",
    "        temp += document_contents[i][j] + ' '\n",
    "    contents.append(temp)\n",
    "\n",
    "# left inner join of DataFrames\n",
    "# all_document_data contains information on all documents with content that have also metadata\n",
    "name_contents = pd.DataFrame(columns=['Filename','Content'])\n",
    "name_contents['Filename'] = filenames\n",
    "name_contents['Content'] = contents\n",
    "all_document_data = pd.merge(all_document_data,name_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:09:55.203249Z",
     "start_time": "2019-06-14T20:09:54.986847Z"
    }
   },
   "outputs": [],
   "source": [
    "# verify which documents are missing from the previous DataFrame\n",
    "s1 = set(all_document_data['Filename'])\n",
    "s2 = set(name_contents['Filename'])\n",
    "no_metadata = list(s2.difference(s1))\n",
    "\n",
    "# create another DataFrame that contains only the filename, \n",
    "# source language, target language and content of these documents\n",
    "no_metadata_source_langs = []\n",
    "no_metadata_target_langs = []\n",
    "no_metadata_contents = []\n",
    "\n",
    "for i in no_metadata:\n",
    "    j = filenames.index(i)\n",
    "    no_metadata_source_langs.append(document_source_langs[j])\n",
    "    no_metadata_target_langs.append(document_target_langs[j])\n",
    "    no_metadata_contents.append(contents[j])\n",
    "\n",
    "no_metadata_df = pd.DataFrame(columns=['Filename', 'Source_lang', 'Target_lang', 'Content'])\n",
    "no_metadata_df['Source_lang'] = no_metadata_source_langs\n",
    "no_metadata_df['Target_lang'] = no_metadata_target_langs\n",
    "no_metadata_df['Content'] = no_metadata_contents\n",
    "no_metadata_df['Filename'] = no_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:10:04.480364Z",
     "start_time": "2019-06-14T20:10:01.717190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/antonis/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "#from nltk.stem import LancasterStemmer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def stemSentence(sentence):\n",
    "    token_words=tokenizer.tokenize(sentence)\n",
    "    token_words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    #print(stop_words)\n",
    "    filter_sentense = [w for w in token_words if not w in stop_words]\n",
    "    \n",
    "    stem_sentence=[]\n",
    "    for word in filter_sentense:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:10:08.732474Z",
     "start_time": "2019-06-14T20:10:08.728414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REACH_BGD_JENA_C26_BT_F_2.docx\n",
      "Name:  নাম  নিগার সোলতানা  Venue: স্থান  ক্যাম্প ২৬  Number of Participants: \n",
      "অংশগ্রহণকারীদের সংখ্যা ১০  Type of Participants: \n",
      "অংশগ্রহণকারীদের প্রকার Time: সময়  ১১.৩০ সকাল বেলা   Date: তারিখ  ২৪.০২.২০১৯  Note: Note: নির্দেশ আইসিই বিরতি অংশ INSERT SECTION NAME ইনসার্ট বিভাগ নাম INSERT PART ইনসার্ট অংশ Respondent উত্তরদাতা #   R9 উনি মনে করেন উনি ১০০% নিরাপদ R1 sapacc টা বড় না। ওখানে খেলা ধুলা করার জায়গা বড় না। R7 বাচ্চারা লেখাপড়া করতে চাই যদি খেলাধুলা বেশি দিলে ওরা বেশি করে পড়ালেখা করতে চাই। R5 স্কুলের পাশে জায়গা আছে। আগে ওখানে গেলে তারা আর স্কুলে আসত না। লেখাপড়া করতে আসেনা কারণ ওরা খেলা করে।  টাইম টা সেইম তাই R3 স্কুলে যেতে অনেক কষ্ট হয়। ওখানে স্কুলে চুর ডুকে। স্কুল্টা নিরাপদ না। রাস্তার পাশে স্কুল, বিভিন্ন লোক ওসে আড্ডা দেয়।  R5 স্কুলটা রাস্তার পাশে। ওখান কার ছেলেরা এসে ডিস্টার্ব করে। ওখানে পানির সমস্যা অনেক। আচর ভেঙ্গে পড়েছে।  R3 ক্লাস রোম টা যদি বড় হত তাইলে ভাল হত। ওদের জন্য সুবিধা হত পড়ত। R9 বড় হত তাইলে ভাল হত। বাইরে বারান্দাটা বড় হলে আরেকটু খেলা করতে সুবিধা হত।  R4 এখন তো বার্মিজ পড়ায়। যদি ইংরেজি আর গণিত দিত ভালই হত।  R8 খাতা কলম বই বেশি দিলে ভালই হত। যদি খাতা না দেয় তাইলে ওরা আসেনা।  হ্যাঁ পাবে। R4 প্রথম শিফট ভাল। (৯-১১)। আসতে ১০ টা বাজে।  দ্বিতীয় শিফট ভাল না। (১১-২) R12 প্রথম শিফট ভাল। (৯-১১.৩০) ২০ টা মেয়ে ১৫ টা ছেলে।  দ্বিতীয় শিফট (১১.৩০-২) মেয়েরা একটু বড় হয়ে গেছে তাই আসতে চাইনা।  R11 প্রথম শিফট ভাল। (৯-১১.৩০) দ্বিতীয় শিফট ভাল না। (১১.৩০-২) R1 প্রথম শিফট ভাল। (৯-১১.৩০) দ্বিতীয় শিফট ভাল না। (১১.৩০-২) ২ টাই ক্লোস করতে বলে সি আই সি ওদের অসুক হলে কোন স্কুলে রেফার করার সুবিধা নেই।  এই রকম সমমোকিন কোন দিন ও হয় নাই।  প্রতিবন্ধি বাচ্চাদের সামনে বসায় পাঠদান করাই।  সবাই প্রতিবন্ধিদের উপর ট্রেইনিং পাইছে।  সবাই ট্রেইনিং নিতে চাই।  ওরা কিভাবে পড়ানো যায়। কিভাবে শিখানো যায়। তার উপর ভাল করে যেন পড়াতে পারে।  হেলথ ট্রেইনিং সবাই পাইছে।  প্রথম এইড বক্স দরকার ওদের থেকে সবকিছু দিতে হয়। ট্রেইনিং ইন্টার্ভিউ  ওরা সোজাসোজি ভাবে শিক্ষকতায় ডুকতে পারেনা।  R1 R2 R3 ওদের থেকে হেঠে আসতে কষ্ট হয়।  স্কুলের জন্য ঘিরা লাগবে। দারোয়ান লাগবে। ছাদের নিচে কাপড়, শিক্ষকের জন্য ব্যাগ, ছাতা লাগবে। বৃষ্টি দিলে ছিটকি না ডুকে। R2 স্কুলের চারপাশে মাঠি সমান করে দেই।  R4 স্কুলের পাশে গন্ধ না উঠার ব্যবস্থা করা।  সবাই মাসে ২ বার মিটিং করে বাচ্চাদের মা বাবাদের নিয়ে মিটিং করে।  R3 সবাই চাই প্রত্যেক সপ্তাহে যেন ওদের সাথে মিটিং করার ব্যবস্থা করে দিই।  R4 ভাল, খারাপ ছেলে, আচার আচরণ ভাষা আগের চেয়ে অনেক উন্নতি হয়েছে।  R1 যারা লিকতে জানতনা তারা এখন লিখতে জানে। যারা পড়তে জানতনা তারা পড়তে যানে।  R3 তারা শিখার ক্ষেত্রে ভাষা, ব্যবহার, আচার আচরণ পরিষ্কার সব কিছু পরিবর্তন হয়েছে। অবনতি কিছুই হয়নাই।     \n",
      "['REACH_BGD_JENA_C26_BT_F_2', 'docx']\n"
     ]
    }
   ],
   "source": [
    "# testing tokenizer function\n",
    "n=16880\n",
    "filename = all_document_data['Filename'].iloc[n]\n",
    "sentence = all_document_data['Content'].iloc[n]\n",
    "token_words = tokenizer.tokenize(filename)\n",
    "print(filename)\n",
    "print(sentence)\n",
    "print(token_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:10:12.520069Z",
     "start_time": "2019-06-14T20:10:12.509848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'ন', 'ম', 'ন', 'গ', 'র', 'স', 'লত', 'ন', 'venu', 'স', 'থ', 'ন', 'ক', 'য', 'ম', 'প', '২৬', 'number', 'particip', 'অ', 'শগ', 'রহণক', 'র', 'দ', 'র', 'স', 'খ', 'য', '১০', 'type', 'particip', 'অ', 'শগ', 'রহণক', 'র', 'দ', 'র', 'প', 'রক', 'র', 'time', 'সময়', '১১', '৩০', 'সক', 'ল', 'ব', 'ল', 'date', 'ত', 'র', 'খ', '২৪', '০২', '২০১৯', 'note', 'note', 'ন', 'র', 'দ', 'শ', 'আইস', 'ই', 'ব', 'রত', 'অ', 'শ', 'insert', 'section', 'name', 'ইনস', 'র', 'ট', 'ব', 'ভ', 'গ', 'ন', 'ম', 'insert', 'part', 'ইনস', 'র', 'ট', 'অ', 'শ', 'respond', 'উত', 'তরদ', 'ত', 'R9', 'উন', 'মন', 'কর', 'ন', 'উন', '১০০', 'ন', 'র', 'পদ', 'R1', 'sapacc', 'ট', 'বড়', 'ন', 'ওখ', 'ন', 'খ', 'ল', 'ধ', 'ল', 'কর', 'র', 'জ', 'য়গ', 'বড়', 'ন', 'R7', 'ব', 'চ', 'চ', 'র', 'ল', 'খ', 'পড়', 'করত', 'চ', 'ই', 'যদ', 'খ', 'ল', 'ধ', 'ল', 'ব', 'শ', 'দ', 'ল', 'ওর', 'ব', 'শ', 'কর', 'পড়', 'ল', 'খ', 'করত', 'চ', 'ই', 'R5', 'স', 'ক', 'ল', 'র', 'প', 'শ', 'জ', 'য়গ', 'আছ', 'আগ', 'ওখ', 'ন', 'গ', 'ল', 'ত', 'র', 'আর', 'স', 'ক', 'ল', 'আসত', 'ন', 'ল', 'খ', 'পড়', 'করত', 'আস', 'ন', 'ক', 'রণ', 'ওর', 'খ', 'ল', 'কর', 'ট', 'ইম', 'ট', 'স', 'ইম', 'ত', 'ই', 'R3', 'স', 'ক', 'ল', 'য', 'ত', 'অন', 'ক', 'কষ', 'ট', 'হয়', 'ওখ', 'ন', 'স', 'ক', 'ল', 'চ', 'র', 'ড', 'ক', 'স', 'ক', 'ল', 'ট', 'ন', 'র', 'পদ', 'ন', 'র', 'স', 'ত', 'র', 'প', 'শ', 'স', 'ক', 'ল', 'ব', 'ভ', 'ন', 'ন', 'ল', 'ক', 'ওস', 'আড', 'ড', 'দ', 'য়', 'R5', 'স', 'ক', 'লট', 'র', 'স', 'ত', 'র', 'প', 'শ', 'ওখ', 'ন', 'ক', 'র', 'ছ', 'ল', 'র', 'এস', 'ড', 'স', 'ট', 'র', 'ব', 'কর', 'ওখ', 'ন', 'প', 'ন', 'র', 'সমস', 'য', 'অন', 'ক', 'আচর', 'ভ', 'ঙ', 'গ', 'পড়', 'ছ', 'R3', 'ক', 'ল', 'স', 'র', 'ম', 'ট', 'যদ', 'বড়', 'হত', 'ত', 'ইল', 'ভ', 'ল', 'হত', 'ওদ', 'র', 'জন', 'য', 'স', 'ব', 'ধ', 'হত', 'পড়ত', 'R9', 'বড়', 'হত', 'ত', 'ইল', 'ভ', 'ল', 'হত', 'ব', 'ইর', 'ব', 'র', 'ন', 'দ', 'ট', 'বড়', 'হল', 'আর', 'কট', 'খ', 'ল', 'করত', 'স', 'ব', 'ধ', 'হত', 'R4', 'এখন', 'ত', 'ব', 'র', 'ম', 'জ', 'পড়', 'য়', 'যদ', 'ই', 'র', 'জ', 'আর', 'গণ', 'ত', 'দ', 'ত', 'ভ', 'লই', 'হত', 'R8', 'খ', 'ত', 'কলম', 'বই', 'ব', 'শ', 'দ', 'ল', 'ভ', 'লই', 'হত', 'যদ', 'খ', 'ত', 'ন', 'দ', 'য়', 'ত', 'ইল', 'ওর', 'আস', 'ন', 'হ', 'য', 'প', 'ব', 'R4', 'প', 'রথম', 'শ', 'ফট', 'ভ', 'ল', '৯', '১১', 'আসত', '১০', 'ট', 'ব', 'জ', 'দ', 'ব', 'ত', 'য়', 'শ', 'ফট', 'ভ', 'ল', 'ন', '১১', '২', 'r12', 'প', 'রথম', 'শ', 'ফট', 'ভ', 'ল', '৯', '১১', '৩০', '২০', 'ট', 'ম', 'য়', '১৫', 'ট', 'ছ', 'ল', 'দ', 'ব', 'ত', 'য়', 'শ', 'ফট', '১১', '৩০', '২', 'ম', 'য়', 'র', 'একট', 'বড়', 'হয়', 'গ', 'ছ', 'ত', 'ই', 'আসত', 'চ', 'ইন', 'r11', 'প', 'রথম', 'শ', 'ফট', 'ভ', 'ল', '৯', '১১', '৩০', 'দ', 'ব', 'ত', 'য়', 'শ', 'ফট', 'ভ', 'ল', 'ন', '১১', '৩০', '২', 'R1', 'প', 'রথম', 'শ', 'ফট', 'ভ', 'ল', '৯', '১১', '৩০', 'দ', 'ব', 'ত', 'য়', 'শ', 'ফট', 'ভ', 'ল', 'ন', '১১', '৩০', '২', '২', 'ট', 'ই', 'ক', 'ল', 'স', 'করত', 'বল', 'স', 'আই', 'স', 'ওদ', 'র', 'অস', 'ক', 'হল', 'ক', 'ন', 'স', 'ক', 'ল', 'র', 'ফ', 'র', 'কর', 'র', 'স', 'ব', 'ধ', 'ন', 'ই', 'এই', 'রকম', 'সমম', 'ক', 'ন', 'ক', 'ন', 'দ', 'ন', 'ও', 'হয়', 'ন', 'ই', 'প', 'রত', 'বন', 'ধ', 'ব', 'চ', 'চ', 'দ', 'র', 'স', 'মন', 'বস', 'য়', 'প', 'ঠদ', 'ন', 'কর', 'ই', 'সব', 'ই', 'প', 'রত', 'বন', 'ধ', 'দ', 'র', 'উপর', 'ট', 'র', 'ইন', 'প', 'ইছ', 'সব', 'ই', 'ট', 'র', 'ইন', 'ন', 'ত', 'চ', 'ই', 'ওর', 'ক', 'ভ', 'ব', 'পড়', 'ন', 'য', 'য়', 'ক', 'ভ', 'ব', 'শ', 'খ', 'ন', 'য', 'য়', 'ত', 'র', 'উপর', 'ভ', 'ল', 'কর', 'য', 'ন', 'পড়', 'ত', 'প', 'র', 'হ', 'লথ', 'ট', 'র', 'ইন', 'সব', 'ই', 'প', 'ইছ', 'প', 'রথম', 'এইড', 'বক', 'স', 'দরক', 'র', 'ওদ', 'র', 'থ', 'ক', 'সবক', 'ছ', 'দ', 'ত', 'হয়', 'ট', 'র', 'ইন', 'ইন', 'ট', 'র', 'ভ', 'উ', 'ওর', 'স', 'জ', 'স', 'জ', 'ভ', 'ব', 'শ', 'ক', 'ষকত', 'য়', 'ড', 'কত', 'প', 'র', 'ন', 'R1', 'R2', 'R3', 'ওদ', 'র', 'থ', 'ক', 'হ', 'ঠ', 'আসত', 'কষ', 'ট', 'হয়', 'স', 'ক', 'ল', 'র', 'জন', 'য', 'ঘ', 'র', 'ল', 'গব', 'দ', 'র', 'য়', 'ন', 'ল', 'গব', 'ছ', 'দ', 'র', 'ন', 'চ', 'ক', 'পড়', 'শ', 'ক', 'ষক', 'র', 'জন', 'য', 'ব', 'য', 'গ', 'ছ', 'ত', 'ল', 'গব', 'ব', 'ষ', 'ট', 'দ', 'ল', 'ছ', 'টক', 'ন', 'ড', 'ক', 'R2', 'স', 'ক', 'ল', 'র', 'চ', 'রপ', 'শ', 'ম', 'ঠ', 'সম', 'ন', 'কর', 'দ', 'ই', 'R4', 'স', 'ক', 'ল', 'র', 'প', 'শ', 'গন', 'ধ', 'ন', 'উঠ', 'র', 'ব', 'যবস', 'থ', 'কর', 'সব', 'ই', 'ম', 'স', '২', 'ব', 'র', 'ম', 'ট', 'কর', 'ব', 'চ', 'চ', 'দ', 'র', 'ম', 'ব', 'ব', 'দ', 'র', 'ন', 'য়', 'ম', 'ট', 'কর', 'R3', 'সব', 'ই', 'চ', 'ই', 'প', 'রত', 'য', 'ক', 'সপ', 'ত', 'হ', 'য', 'ন', 'ওদ', 'র', 'স', 'থ', 'ম', 'ট', 'কর', 'র', 'ব', 'যবস', 'থ', 'কর', 'দ', 'ই', 'R4', 'ভ', 'ল', 'খ', 'র', 'প', 'ছ', 'ল', 'আচ', 'র', 'আচরণ', 'ভ', 'ষ', 'আগ', 'র', 'চ', 'য়', 'অন', 'ক', 'উন', 'নত', 'হয়', 'ছ', 'R1', 'য', 'র', 'ল', 'কত', 'জ', 'নতন', 'ত', 'র', 'এখন', 'ল', 'খত', 'জ', 'ন', 'য', 'র', 'পড়ত', 'জ', 'নতন', 'ত', 'র', 'পড়ত', 'য', 'ন', 'R3', 'ত', 'র', 'শ', 'খ', 'র', 'ক', 'ষ', 'ত', 'র', 'ভ', 'ষ', 'ব', 'যবহ', 'র', 'আচ', 'র', 'আচরণ', 'পর', 'ষ', 'ক', 'র', 'সব', 'ক', 'ছ', 'পর', 'বর', 'তন', 'হয়', 'ছ', 'অবনত', 'ক', 'ছ', 'ই', 'হয়ন', 'ই']\n"
     ]
    }
   ],
   "source": [
    "# testing stemSentence function\n",
    "x=tokenizer.tokenize(stemSentence(sentence))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:17:33.153249Z",
     "start_time": "2019-06-14T20:10:27.156976Z"
    }
   },
   "outputs": [],
   "source": [
    "# create pd data frame \"Stems\" and save all the stemed Filenames and Content\n",
    "stems = pd.DataFrame(index=all_document_data.index, columns=['Filename','Content'])\n",
    "for i in all_document_data.index:\n",
    "    filename = all_document_data['Filename'].iloc[i]\n",
    "    content = all_document_data['Content'].iloc[i]\n",
    "    stems.Filename[i] = stemSentence(filename.replace(\"_\", \" \"))\n",
    "    stems.Content[i] = stemSentence(content.replace(\"_\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:01.129862Z",
     "start_time": "2019-06-14T20:37:01.110662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 0        thi test thi test thi test thi test thi test t...\n",
       "1        thi test thi test thi test thi test thi test t...\n",
       "2        thi test thi test thi test thi test thi test t...\n",
       "3        thi test thi test thi test thi test thi test t...\n",
       "4        thi test thi test thi test thi test thi test t...\n",
       "5        thi test thi test thi test thi test thi test t...\n",
       "6        thi test thi test thi test thi test thi test t...\n",
       "7        thi test thi test thi test thi test thi test t...\n",
       "8        thi test thi test thi test thi test thi test t...\n",
       "9        thi test thi test thi test thi test thi test t...\n",
       "10       thi test thi test thi test thi test thi test t...\n",
       "11       thi test thi test thi test thi test thi test t...\n",
       "12       global tool review final report 30 novemb 2016...\n",
       "13       global tool review final report 30 novemb 2016...\n",
       "14       global tool review final report 30 novemb 2016...\n",
       "15       includ AN imag map OR pictur format cover page...\n",
       "16       execut summari thi report repres first phase o...\n",
       "17       all hazard prevent make household emerg evacu ...\n",
       "18       all hazard prevent make household emerg evacu ...\n",
       "19       all hazard prevent make household emerg evacu ...\n",
       "20       all hazard prevent make household emerg evacu ...\n",
       "21       all hazard prevent make household emerg evacu ...\n",
       "22       all hazard prevent make household emerg evacu ...\n",
       "23       all hazard prevent make household emerg evacu ...\n",
       "24       all hazard prevent make household emerg evacu ...\n",
       "25       all hazard prevent make household emerg evacu ...\n",
       "26       all hazard prevent make household emerg evacu ...\n",
       "27       all hazard prevent make household emerg evacu ...\n",
       "28       all hazard prevent make household emerg evacu ...\n",
       "29       all hazard prevent make household emerg evacu ...\n",
       "                               ...                        \n",
       "16866    name ন ম আবদ ল ক দ র venu স থ ন number partici...\n",
       "16867    name ন ম fgd venu স থ ন number particip অ শগ র...\n",
       "16868    name ন ম fgd venu স থ ন number particip অ শগ র...\n",
       "16869    name ন ম fgd venu স থ ন number particip অ শগ র...\n",
       "16870    name ন ম fgd venu স থ ন number particip অ শগ র...\n",
       "16871    name ন ম আয়শ venu স থ ন ক য ম প ২৬ number part...\n",
       "16872    name ন ম আয়শ venu স থ ন ক য ম প ২৬ number part...\n",
       "16873    name ন ম আয়শ venu স থ ন ক য ম প ২৬ number part...\n",
       "16874    name ন ম শ ফ venu স থ ন ২৬ number particip অ শ...\n",
       "16875    name ন ম শ ফ venu স থ ন ২৬ number particip অ শ...\n",
       "16876    name ন ম শ ফ venu স থ ন ২৬ number particip অ শ...\n",
       "16877    name ন ম শ ফ venu স থ ন ২৬ number particip অ শ...\n",
       "16878    name ন ম শ ফ venu স থ ন ২৬ number particip অ শ...\n",
       "16879    name ন ম ন গ র স লত ন venu স থ ন ক য ম প ২৬ nu...\n",
       "16880    name ন ম ন গ র স লত ন venu স থ ন ক য ম প ২৬ nu...\n",
       "16881    name ন ম ন গ র স লত ন venu স থ ন ক য ম প ২৬ nu...\n",
       "16882    name ন ম আজ হ র আলম র ব ব venu স থ ন number pa...\n",
       "16883    name ন ম আজ হ র আলম র ব ব venu স থ ন number pa...\n",
       "16884    name ন ম আজ হ র আলম র ব ব venu স থ ন number pa...\n",
       "16885    name ন ম দ ল য় র ইসল ম venu স থ ন number parti...\n",
       "16886    name ন ম দ ল য় র ইসল ম venu স থ ন number parti...\n",
       "16887    name ন ম দ ল য় র ইসল ম venu স থ ন number parti...\n",
       "16888    name ন ম আয় শ আকত র venu স থ ন ক য ম প ৫ ১৭ nu...\n",
       "16889    name ন ম আয় শ আকত র venu স থ ন ক য ম প ৫ ১৭ nu...\n",
       "16890    name ন ম আয় শ আকত র venu স থ ন ক য ম প ৫ ১৭ nu...\n",
       "16891    name ন ম আবদ ল ক দ র venu স থ ন number partici...\n",
       "16892    name ন ম আবদ ল ক দ র venu স থ ন number partici...\n",
       "16893    name ন ম আবদ ল ক দ র venu স থ ন number partici...\n",
       "16894    twb languag barrier research onlin survey cox ...\n",
       "16895    project A nice place foundat durat 2 year loca...\n",
       "Name: Content, Length: 16896, dtype: object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems.Content.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:05.105479Z",
     "start_time": "2019-06-14T20:37:05.096382Z"
    }
   },
   "outputs": [],
   "source": [
    "tags = ['humanitarian crisis',\n",
    "        'natural disaster',\n",
    "        'environmental crisis',        \n",
    "        'disability',\n",
    "        'gender',\n",
    "        'genital mutilation',\n",
    "        'racism',\n",
    "        'genocide',\n",
    "        'civil war',\n",
    "        'terrorism',\n",
    "        'infectious disease',\n",
    "        'political revolution',\n",
    "        'political prisoner',\n",
    "        'amnesty',\n",
    "        'corruption',\n",
    "        'health awareness',\n",
    "        'gender inequality',\n",
    "        'rape',\n",
    "        'ebola',\n",
    "        'aids',\n",
    "        'first aid',\n",
    "        'emergency',\n",
    "        'disease',\n",
    "        'operation',\n",
    "        'virus',\n",
    "        'response',\n",
    "        'protocol',\n",
    "        'certificate',\n",
    "        'disability', \n",
    "        'medication'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:08.987612Z",
     "start_time": "2019-06-14T20:37:08.981821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humanitarian crisi '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemSentence(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:12.835502Z",
     "start_time": "2019-06-14T20:37:12.814136Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stemming the tags and saving them to a df \n",
    "impactful_dict = pd.DataFrame(index=range(len(tags)), columns=['Stems'])\n",
    "i =0\n",
    "for w in tags:\n",
    "    impactful_dict.Stems[i]= stemSentence(w)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:16.705373Z",
     "start_time": "2019-06-14T20:37:16.689737Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                   Stems\n",
       "0   humanitarian crisi \n",
       "1         natur disast \n",
       "2    environment crisi \n",
       "3               disabl \n",
       "4               gender \n",
       "5          genit mutil \n",
       "6               racism \n",
       "7              genocid \n",
       "8            civil war \n",
       "9               terror \n",
       "10      infecti diseas \n",
       "11       polit revolut \n",
       "12        polit prison \n",
       "13             amnesti \n",
       "14             corrupt \n",
       "15         health awar \n",
       "16        gender inequ \n",
       "17                rape \n",
       "18               ebola \n",
       "19                 aid \n",
       "20           first aid \n",
       "21               emerg \n",
       "22              diseas \n",
       "23                oper \n",
       "24                viru \n",
       "25             respons \n",
       "26            protocol \n",
       "27              certif \n",
       "28              disabl \n",
       "29               medic >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impactful_dict.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Relative Freqs of tags in the Contents and Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:20.588533Z",
     "start_time": "2019-06-14T20:37:20.586256Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:24.375129Z",
     "start_time": "2019-06-14T20:37:24.371035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n",
      "87\n",
      "0.5028901734104047\n"
     ]
    }
   ],
   "source": [
    "# testing word counts and freqs\n",
    "text = stems.Content[0]\n",
    "# text = 'paok paok paok paok paok paok paok test'\n",
    "givenWord = 'test'\n",
    "total = len(re.findall(r'\\w+', text)) \n",
    "count = len(re.findall('\\w*'+ givenWord +'\\w*', text))\n",
    "print(total)\n",
    "print(count)\n",
    "print(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:48.021166Z",
     "start_time": "2019-06-14T20:37:48.014708Z"
    }
   },
   "outputs": [],
   "source": [
    "# function that returns the relative freq of spercific word in str\n",
    "def word_relativ_Freq(text, givenWord):\n",
    "    total = len(re.findall(r'\\w+', text)) \n",
    "    count = len(re.findall('\\w*'+ givenWord +'\\w*', text))\n",
    "    if total==0:\n",
    "        return 0\n",
    "    relFreq = count/total\n",
    "    return relFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:37:51.931947Z",
     "start_time": "2019-06-14T20:37:51.900734Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a data frame with the relative freqs of stemed tags per document content\n",
    "freq_content = pd.DataFrame(index= all_document_data.index, columns=impactful_dict.Stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:44:47.312084Z",
     "start_time": "2019-06-14T20:37:55.808680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 411.5003261566162 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for j in impactful_dict.Stems:\n",
    "    freq_content[j] = stems.Content.apply(lambda x: word_relativ_Freq(x,j))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:45:49.341342Z",
     "start_time": "2019-06-14T20:45:49.221843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stems</th>\n",
       "      <th>humanitarian crisi</th>\n",
       "      <th>natur disast</th>\n",
       "      <th>environment crisi</th>\n",
       "      <th>disabl</th>\n",
       "      <th>gender</th>\n",
       "      <th>genit mutil</th>\n",
       "      <th>racism</th>\n",
       "      <th>genocid</th>\n",
       "      <th>civil war</th>\n",
       "      <th>terror</th>\n",
       "      <th>...</th>\n",
       "      <th>first aid</th>\n",
       "      <th>emerg</th>\n",
       "      <th>diseas</th>\n",
       "      <th>oper</th>\n",
       "      <th>viru</th>\n",
       "      <th>respons</th>\n",
       "      <th>protocol</th>\n",
       "      <th>certif</th>\n",
       "      <th>disabl</th>\n",
       "      <th>medic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>1.689600e+04</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1.200276e-08</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>1.103177e-06</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.004079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>1.013993e-04</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.068531</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.005726</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.061856</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.119565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Stems  humanitarian crisi   natur disast   environment crisi        disabl   \\\n",
       "count         16896.000000   16896.000000        1.689600e+04  16896.000000   \n",
       "mean              0.000014       0.000058        1.200276e-08      0.001530   \n",
       "std               0.000258       0.000872        1.103177e-06      0.007228   \n",
       "min               0.000000       0.000000        0.000000e+00      0.000000   \n",
       "25%               0.000000       0.000000        0.000000e+00      0.000000   \n",
       "50%               0.000000       0.000000        0.000000e+00      0.000000   \n",
       "75%               0.000000       0.000000        0.000000e+00      0.000000   \n",
       "max               0.023256       0.047170        1.013993e-04      0.125874   \n",
       "\n",
       "Stems       gender   genit mutil        racism       genocid     civil war   \\\n",
       "count  16896.000000  16896.000000  16896.000000  16896.000000  16896.000000   \n",
       "mean       0.000531      0.000012      0.000005      0.000002      0.000011   \n",
       "std        0.002931      0.000220      0.000106      0.000086      0.000237   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.068531      0.013333      0.005726      0.006494      0.010870   \n",
       "\n",
       "Stems       terror       ...         first aid         emerg        diseas   \\\n",
       "count  16896.000000      ...       16896.000000  16896.000000  16896.000000   \n",
       "mean       0.000012      ...           0.000355      0.001115      0.001220   \n",
       "std        0.000164      ...           0.003567      0.003953      0.005550   \n",
       "min        0.000000      ...           0.000000      0.000000      0.000000   \n",
       "25%        0.000000      ...           0.000000      0.000000      0.000000   \n",
       "50%        0.000000      ...           0.000000      0.000000      0.000000   \n",
       "75%        0.000000      ...           0.000000      0.000000      0.000000   \n",
       "max        0.004057      ...           0.166667      0.111111      0.103093   \n",
       "\n",
       "Stems         oper          viru       respons      protocol        certif   \\\n",
       "count  16896.000000  16896.000000  16896.000000  16896.000000  16896.000000   \n",
       "mean       0.001218      0.000367      0.002032      0.000143      0.000256   \n",
       "std        0.004004      0.003370      0.008536      0.000902      0.002301   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000296      0.000000      0.001585      0.000000      0.000000   \n",
       "max        0.066667      0.061856      0.166667      0.022543      0.064516   \n",
       "\n",
       "Stems       disabl         medic   \n",
       "count  16896.000000  16896.000000  \n",
       "mean       0.001530      0.000921  \n",
       "std        0.007228      0.004079  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max        0.125874      0.119565  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_content.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:46:01.603314Z",
     "start_time": "2019-06-14T20:45:58.530700Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a data frame with the relative freqs of stemed tags per document filename\n",
    "freq_filename = pd.DataFrame(index= all_document_data.index, columns=impactful_dict.Stems)\n",
    "for j in impactful_dict.Stems:\n",
    "    freq_filename[j] = stems.Filename.apply(lambda x: word_relativ_Freq(x,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:46:05.690322Z",
     "start_time": "2019-06-14T20:46:05.553590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stems</th>\n",
       "      <th>humanitarian crisi</th>\n",
       "      <th>natur disast</th>\n",
       "      <th>environment crisi</th>\n",
       "      <th>disabl</th>\n",
       "      <th>gender</th>\n",
       "      <th>genit mutil</th>\n",
       "      <th>racism</th>\n",
       "      <th>genocid</th>\n",
       "      <th>civil war</th>\n",
       "      <th>terror</th>\n",
       "      <th>...</th>\n",
       "      <th>first aid</th>\n",
       "      <th>emerg</th>\n",
       "      <th>diseas</th>\n",
       "      <th>oper</th>\n",
       "      <th>viru</th>\n",
       "      <th>respons</th>\n",
       "      <th>protocol</th>\n",
       "      <th>certif</th>\n",
       "      <th>disabl</th>\n",
       "      <th>medic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.0</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.0</td>\n",
       "      <td>16896.0</td>\n",
       "      <td>16896.0</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "      <td>16896.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>0.018674</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.007842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Stems  humanitarian crisi   natur disast   environment crisi        disabl   \\\n",
       "count         16896.000000   16896.000000             16896.0  16896.000000   \n",
       "mean              0.000006       0.000010                 0.0      0.000891   \n",
       "std               0.000769       0.001282                 0.0      0.011385   \n",
       "min               0.000000       0.000000                 0.0      0.000000   \n",
       "25%               0.000000       0.000000                 0.0      0.000000   \n",
       "50%               0.000000       0.000000                 0.0      0.000000   \n",
       "75%               0.000000       0.000000                 0.0      0.000000   \n",
       "max               0.100000       0.166667                 0.0      0.250000   \n",
       "\n",
       "Stems       gender   genit mutil   racism   genocid     civil war   terror   \\\n",
       "count  16896.000000       16896.0  16896.0   16896.0  16896.000000  16896.0   \n",
       "mean       0.000373           0.0      0.0       0.0      0.000009      0.0   \n",
       "std        0.008677           0.0      0.0       0.0      0.000690      0.0   \n",
       "min        0.000000           0.0      0.0       0.0      0.000000      0.0   \n",
       "25%        0.000000           0.0      0.0       0.0      0.000000      0.0   \n",
       "50%        0.000000           0.0      0.0       0.0      0.000000      0.0   \n",
       "75%        0.000000           0.0      0.0       0.0      0.000000      0.0   \n",
       "max        0.333333           0.0      0.0       0.0      0.062500      0.0   \n",
       "\n",
       "Stems      ...         first aid         emerg        diseas          oper   \\\n",
       "count      ...       16896.000000  16896.000000  16896.000000  16896.000000   \n",
       "mean       ...           0.000598      0.001309      0.001644      0.000290   \n",
       "std        ...           0.011961      0.015468      0.018674      0.006241   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           0.250000      0.333333      0.333333      0.200000   \n",
       "\n",
       "Stems         viru       respons      protocol        certif        disabl   \\\n",
       "count  16896.000000  16896.000000  16896.000000  16896.000000  16896.000000   \n",
       "mean       0.000033      0.001618      0.000566      0.000433      0.000891   \n",
       "std        0.001813      0.017025      0.010044      0.009764      0.011385   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.142857      0.500000      0.250000      0.333333      0.250000   \n",
       "\n",
       "Stems        medic   \n",
       "count  16896.000000  \n",
       "mean       0.000393  \n",
       "std        0.007842  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        0.250000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_filename.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding labels of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T20:46:11.893837Z",
     "start_time": "2019-06-14T20:46:11.675606Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining function to check buzz word \n",
    "def exist_(temp,j): \n",
    "    temp2=temp.lower()\n",
    "    temp3=temp2.find(j)\n",
    "    return temp3>0\n",
    "    \n",
    "dictionary2=['certificate','instruction','poster','protocol','response','letter','report','map','manual']\n",
    "\n",
    "for j in dictionary2:\n",
    "    jj=all_document_data.Filename.apply(lambda x: exist_(x,j))\n",
    "    rr=pd.DataFrame(columns=[str(j)])\n",
    "    rr[str(j)]=jj\n",
    "    all_document_data=pd.concat([all_document_data,rr ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "50"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
