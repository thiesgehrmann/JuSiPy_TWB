{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library and Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import TWB.xliff as xliff\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import queue\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your data path here\n",
    "data_dir = '/home/mixalis/Downloads/Translators Without Borders/'\n",
    "metadata = pd.read_excel(data_dir + 'Hackathon-for-Good-2019_TWB-Challenge_Metadata.xlsx')\n",
    "\n",
    "# choose only text documents\n",
    "# TODO The metadata contain some files multiple times and the table is almost 3 times the number of documents\n",
    "# Using various combinations of subsets of the columns to get all the 12156 documents did not succeed\n",
    "accepted_documents = metadata.loc[metadata['Format'] == 'doc'].drop_duplicates()\n",
    "\n",
    "# update data path with the sdlxliff directory\n",
    "data_dir += 'hackathon-for-good-2019_TWB-challenge_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all sdlxliff filenames into a list\n",
    "document_names = []\n",
    "\n",
    "# trying to get all doc documents based on extensions\n",
    "for document in os.listdir(data_dir):    \n",
    "    if fnmatch.fnmatch(document,'*.sdlxliff'):\n",
    "        if fnmatch.fnmatch(document,'*.doc*'):\n",
    "            document_names.append(data_dir + document)\n",
    "        if fnmatch.fnmatch(document,'*.DOC*'):\n",
    "            document_names.append(data_dir + document)\n",
    "        if fnmatch.fnmatch(document,'*.txt*'):\n",
    "            document_names.append(data_dir + document)    \n",
    "        if fnmatch.fnmatch(document,'*.pdf*'):\n",
    "            document_names.append(data_dir + document)\n",
    "        if fnmatch.fnmatch(document,'*.PDF*'):\n",
    "            document_names.append(data_dir + document)\n",
    "        if fnmatch.fnmatch(document,'*.odt*'):\n",
    "            document_names.append(data_dir + document)\n",
    "        if fnmatch.fnmatch(document,'*.rtf*'):\n",
    "            document_names.append(data_dir + document)\n",
    "        if fnmatch.fnmatch(document,'*.dotx*'):\n",
    "            document_names.append(data_dir + document)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the translated contents of all documents\n",
    "document_contents = []\n",
    "\n",
    "for document in list(document_names):\n",
    "    # Avoid a couple of (probably) malformed xml documents(No root found by the parser)\n",
    "    try:\n",
    "        document_contents.append(xliff.XLIFF(document).target)\n",
    "    except AttributeError:\n",
    "        print(document)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIFO queue\n",
    "impact_queue = queue.Queue(len(document_names))\n",
    "\n",
    "# Priority queue with tupes of (priority_number,data) as items, lowest valued entries are retrieved first\n",
    "impact_queue2 = queue.PriorityQueue(len(document_names))\n",
    "\n",
    "# Priority queue seems most proper for our use case\n",
    "# Any change to the queue that does not concern the first element basically requires to create another queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
